{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Latency.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM/XviLoOyNCoasj1f0Uc12",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanmayj2020/HELP-Modified/blob/master/Latency.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTecPFscYSCv",
        "outputId": "5824f120-b5d6-4088-a0f2-2c3fd55cdf63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SINGLE ARCHITECTURE - SINGLE HARDWARE"
      ],
      "metadata": {
        "id": "8r8PPsvQZGZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time \n",
        "import torch\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torch import nn\n",
        "import copy "
      ],
      "metadata": {
        "id": "enGLhU5bdFPt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_latency(model , dummy_input):\n",
        "  device = torch.device(\"cuda\")\n",
        "  model.to(device)\n",
        "  dummy_input = dummy_input.to(device)\n",
        "  starter , ender = torch.cuda.Event(enable_timing = True) , torch.cuda.Event(enable_timing=True)\n",
        "  repetitions = 300\n",
        "  timings =np.zeros((repetitions , 1))\n",
        "  #GPU WARM UP \n",
        "  for _ in range(10):\n",
        "    _ = model(dummy_input)\n",
        "  #MEASURE LATENCY \n",
        "  with torch.no_grad():\n",
        "    for rep in range(repetitions):\n",
        "      starter.record()\n",
        "      _ = model(dummy_input) \n",
        "      ender.record()\n",
        "      #WAIT for GPU sync \n",
        "      torch.cuda.synchronize()\n",
        "      curr_time = starter.elapsed_time(ender)\n",
        "      timings[rep] = curr_time\n",
        "  mean_syn = np.sum(timings)/repetitions\n",
        "  std_syn = np.std(timings)\n",
        "  print(mean_syn)\n",
        "  \n",
        " "
      ],
      "metadata": {
        "id": "dVmNoEakZNL7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_input():\n",
        "  torch.manual_seed(1)\n",
        "  dummy_input = torch.randn(1 , 3 , 224 , 224 , dtype=torch.float)\n",
        "  return dummy_input"
      ],
      "metadata": {
        "id": "Fpmqf42Nc49j"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def alexnet1():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model1 = copy.deepcopy(model) \n",
        "  model1.features[3] = nn.Conv2d(64,100, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model1.features[6] = nn.Conv2d(100,384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model1\n",
        "\n",
        "def alexnet2():\n",
        "  model  = torchvision.models.alexnet(pretrained=True) \n",
        "  model2 = copy.deepcopy(model) \n",
        "  model2.features[3] = nn.Conv2d(64,90, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model2.features[6] = nn.Conv2d(90,384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model2\n",
        "\n",
        "def alexnet3():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model2 = copy.deepcopy(model) \n",
        "  model2.features[3] = nn.Conv2d(64,80, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model2.features[6] = nn.Conv2d(80,384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model2\n",
        "\n",
        "def alexnet4():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model3 = copy.deepcopy(model) \n",
        "  model3.features[3] = nn.Conv2d(64,70, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model3.features[6] = nn.Conv2d(70,384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model3\n",
        "\n",
        "def alexnet5():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model4 = copy.deepcopy(model) \n",
        "  model4.features[3] = nn.Conv2d(64,105, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model4.features[6] = nn.Conv2d(105,384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model4\n",
        "\n",
        "def alexnet6():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model5 = copy.deepcopy(model) \n",
        "  model5.features[3] = nn.Conv2d(64,120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model5.features[6] = nn.Conv2d(120,384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model5\n",
        "  \n",
        "def alexnet7():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model6 = copy.deepcopy(model) \n",
        "  model6.features[3] = nn.Conv2d(64,130, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model6.features[6] = nn.Conv2d(130,384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model6\n",
        "  \n",
        "def alexnet8():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model7 = copy.deepcopy(model) \n",
        "  model7.features[3] = nn.Conv2d(64,140, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model7.features[6] = nn.Conv2d(140,384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model7\n",
        "  \n",
        "def alexnet9():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)  \n",
        "  model8 = copy.deepcopy(model) \n",
        "  model8.features[3] = nn.Conv2d(64,145, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model8.features[6] = nn.Conv2d(145,384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model8\n",
        "  \n",
        "def alexnet10():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model9 = copy.deepcopy(model) \n",
        "  model9.features[3] = nn.Conv2d(64,160, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model9.features[6] = nn.Conv2d(160,384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model9\n",
        "  \n",
        "def alexnet11():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)  \n",
        "  model10 = copy.deepcopy(model) \n",
        "  model10.features[3] = nn.Conv2d(64,170, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model10.features[6] = nn.Conv2d(170,384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model10\n",
        "  \n",
        "def alexnet12():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model11 = copy.deepcopy(model) \n",
        "  model11.features[3] = nn.Conv2d(64,150, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model11.features[6] = nn.Conv2d(150,384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model11\n",
        "  \n",
        "def alexnet13():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)  \n",
        "  model12 = copy.deepcopy(model) \n",
        "  model12.features[3] = nn.Conv2d(64,180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model12.features[6] = nn.Conv2d(180,384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model12\n",
        "  \n",
        "def alexnet14():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model13 = copy.deepcopy(model) \n",
        "  model13.features[6] = nn.Conv2d(192,300, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model13.features[8] = nn.Conv2d(300,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model13\n",
        "  \n",
        "def alexnet15():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model14 = copy.deepcopy(model) \n",
        "  model14.features[6] = nn.Conv2d(192,310, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model14.features[8] = nn.Conv2d(310,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model14\n",
        "  \n",
        "def alexnet16():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model15 = copy.deepcopy(model) \n",
        "  model15.features[6] = nn.Conv2d(192,320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model15.features[8] = nn.Conv2d(320,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model15\n",
        "  \n",
        "def alexnet17():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model16 = copy.deepcopy(model) \n",
        "  model16.features[6] = nn.Conv2d(192,330, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model16.features[8] = nn.Conv2d(330,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model16\n",
        "  \n",
        "def alexnet18():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model17 = copy.deepcopy(model) \n",
        "  model17.features[6] = nn.Conv2d(192,340, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model17.features[8] = nn.Conv2d(340,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model17\n",
        "  \n",
        "def alexnet19():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model18 = copy.deepcopy(model) \n",
        "  model18.features[6] = nn.Conv2d(192,350, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model18.features[8] = nn.Conv2d(350,256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
        "  return model18\n",
        "  \n",
        "def alexnet20():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model19 = copy.deepcopy(model) \n",
        "  model19.features[6] = nn.Conv2d(192,360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model19.features[8] = nn.Conv2d(360,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model19\n",
        "  \n",
        "def alexnet21():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model20 = copy.deepcopy(model) \n",
        "  model20.features[6] = nn.Conv2d(192,370, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model20.features[8] = nn.Conv2d(370,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model20\n",
        "  \n",
        "def alexnet22():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model21 = copy.deepcopy(model) \n",
        "  model21.features[6] = nn.Conv2d(192,380, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model21.features[8] = nn.Conv2d(380,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model21\n",
        "  \n",
        "def alexnet23():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model22 = copy.deepcopy(model) \n",
        "  model22.features[6] = nn.Conv2d(192,200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model22.features[8] = nn.Conv2d(200,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model22\n",
        "  \n",
        "def alexnet24():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model23 = copy.deepcopy(model) \n",
        "  model23.features[6] = nn.Conv2d(192,210, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model23.features[8] = nn.Conv2d(210,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model23\n",
        "  \n",
        "def alexnet25():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model24 = copy.deepcopy(model) \n",
        "  model24.features[6] = nn.Conv2d(192,250, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model24.features[8] = nn.Conv2d(250,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model24\n",
        "  \n",
        "def alexnet26():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model25 = copy.deepcopy(model) \n",
        "  model25.features[6] = nn.Conv2d(192,220, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model25.features[8] = nn.Conv2d(220,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model25\n",
        "  \n",
        "def alexnet27():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model26 = copy.deepcopy(model)\n",
        "  model26.features[0] = nn.Conv2d(3 , 100, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
        "  model26.features[3] = nn.Conv2d(100,150, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model26.features[6] = nn.Conv2d(150,200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model26.features[8] = nn.Conv2d(200,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model26\n",
        "  \n",
        "def alexnet28():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model27 = copy.deepcopy(model) \n",
        "  model27.features[0] = nn.Conv2d(3,90, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
        "  model27.features[3] = nn.Conv2d(90,150, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model27.features[6] = nn.Conv2d(150,240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model27.features[8] = nn.Conv2d(240,256,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model27\n",
        "  \n",
        "def alexnet29():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model28 = copy.deepcopy(model) \n",
        "  model28.features[0] = nn.Conv2d(3,200, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
        "  model28.features[3] = nn.Conv2d(200,220, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model28.features[6] = nn.Conv2d(220,290,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model28.features[8] = nn.Conv2d(290,256,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model28\n",
        "  \n",
        "def alexnet30():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model29 = copy.deepcopy(model) \n",
        "  model29.features[0] = nn.Conv2d(3,180,kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
        "  model29.features[3] = nn.Conv2d(180,360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model29.features[6] = nn.Conv2d(360,420, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model29.features[8] = nn.Conv2d(420,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model29\n",
        "  \n",
        "def alexnet31():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model30 = copy.deepcopy(model) \n",
        "  model30.features[0] = nn.Conv2d(3,70, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
        "  model30.features[3] = nn.Conv2d(70,150, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model30.features[6] = nn.Conv2d(150,210, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model30.features[8] = nn.Conv2d(210,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model30\n",
        "  \n",
        "def alexnet32():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model31 = copy.deepcopy(model) \n",
        "  model31.features[0] = nn.Conv2d(3,110, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
        "  model31.features[3] = nn.Conv2d(110,200, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model31.features[6] = nn.Conv2d(200,192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model31.features[8] = nn.Conv2d(192,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model31\n",
        "  \n",
        "def alexnet33():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model32 = copy.deepcopy(model) \n",
        "  model32.features[0] = nn.Conv2d(3,100,kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
        "  model32.features[3] = nn.Conv2d(100,150, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model32.features[6] = nn.Conv2d(150,300,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model32.features[8] = nn.Conv2d(300,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model32\n",
        "  \n",
        "def alexnet34():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model33 = copy.deepcopy(model) \n",
        "  model33.features[0] = nn.Conv2d(3,80, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
        "  model33.features[3] = nn.Conv2d(80,150, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model33.features[6] = nn.Conv2d(150,200,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model33.features[8] = nn.Conv2d(200,256,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model33\n",
        "  \n",
        "def alexnet35():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model34 = copy.deepcopy(model) \n",
        "  model34.features[0] = nn.Conv2d(3,150, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
        "  model34.features[3] = nn.Conv2d(150,230, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model34.features[6] = nn.Conv2d(230,395,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model34.features[8] = nn.Conv2d(395,256,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model34\n",
        "  \n",
        "def alexnet36():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model35 = copy.deepcopy(model) \n",
        "  model35.features[0] = nn.Conv2d(3,160, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
        "  model35.features[3] = nn.Conv2d(160 ,195, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model35.features[6] = nn.Conv2d(195,240,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model35.features[8] = nn.Conv2d(240,256,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model35\n",
        "  \n",
        "def alexnet37():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model36 = copy.deepcopy(model) \n",
        "  model36.features[0] = nn.Conv2d(3,190, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
        "  model36.features[3] = nn.Conv2d(190,210, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model36.features[6] = nn.Conv2d(210,280,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model36.features[8] = nn.Conv2d(280,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model36\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "W9JJqO0Azqhq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vgg_modified():\n",
        "  model  = torchvision.models.vgg11(pretrained=True)\n",
        "  model1 = copy.deepcopy(model) \n",
        "  model1.features[3] = nn.Conv2d(64,150,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model1.features[6] = nn.Conv2d(150,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  \n",
        "  model2 = copy.deepcopy(model) \n",
        "  model2.features[3] = nn.Conv2d(64,180,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model2.features[6] = nn.Conv2d(180,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "  model2 = copy.deepcopy(model) \n",
        "  model2.features[3] = nn.Conv2d(64,80,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model2.features[6] = nn.Conv2d(80,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "  model3 = copy.deepcopy(model) \n",
        "  model3.features[3] = nn.Conv2d(64,70, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model3.features[6] = nn.Conv2d(70,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "  model4 = copy.deepcopy(model) \n",
        "  model4.features[3] = nn.Conv2d(64,105,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model4.features[6] = nn.Conv2d(105,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "\n",
        "  model5 = copy.deepcopy(model) \n",
        "  model5.features[3] = nn.Conv2d(64,120,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model5.features[6] = nn.Conv2d(120,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "  model6 = copy.deepcopy(model) \n",
        "  model6.features[3] = nn.Conv2d(64,130, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model6.features[6] = nn.Conv2d(130,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "  model7 = copy.deepcopy(model) \n",
        "  model7.features[3] = nn.Conv2d(64,140, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model7.features[6] = nn.Conv2d(140,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "  \n",
        "  model8 = copy.deepcopy(model) \n",
        "  model8.features[3] = nn.Conv2d(64,145, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model8.features[6] = nn.Conv2d(145,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "  \n",
        "  model9 = copy.deepcopy(model) \n",
        "  model9.features[3] = nn.Conv2d(64,160,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model9.features[6] = nn.Conv2d(160,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "  \n",
        "  model10 = copy.deepcopy(model) \n",
        "  model10.features[3] = nn.Conv2d(64,170,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model10.features[6] = nn.Conv2d(170,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "  \n",
        "  model11 = copy.deepcopy(model) \n",
        "  model11.features[3] = nn.Conv2d(64,150,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model11.features[6] = nn.Conv2d(150,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "  \n",
        "  model12 = copy.deepcopy(model) \n",
        "  model12.features[3] = nn.Conv2d(64,180,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model12.features[6] = nn.Conv2d(180,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  model13 = copy.deepcopy(model) \n",
        "  model13.features[6] = nn.Conv2d(128,300,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model13.features[8] = nn.Conv2d(300,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "\n",
        "\n",
        "  model14 = copy.deepcopy(model) \n",
        "  model14.features[6] = nn.Conv2d(128,310,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model14.features[8] = nn.Conv2d(310,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "\n",
        "\n",
        "  model15 = copy.deepcopy(model) \n",
        "  model15.features[6] = nn.Conv2d(128,320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model15.features[8] = nn.Conv2d(320,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "  model16 = copy.deepcopy(model) \n",
        "  model16.features[6] = nn.Conv2d(128,330,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model16.features[8] = nn.Conv2d(330,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "  model17 = copy.deepcopy(model) \n",
        "  model17.features[6] = nn.Conv2d(128,340, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model17.features[8] = nn.Conv2d(340,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "  model18 = copy.deepcopy(model) \n",
        "  model18.features[6] = nn.Conv2d(128,350,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model18.features[8] = nn.Conv2d(350,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "  model19 = copy.deepcopy(model) \n",
        "  model19.features[6] = nn.Conv2d(128,360,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model19.features[8] = nn.Conv2d(360,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "  model20 = copy.deepcopy(model) \n",
        "  model20.features[6] = nn.Conv2d(128,370,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model20.features[8] = nn.Conv2d(370,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "  model21 = copy.deepcopy(model) \n",
        "  model21.features[6] = nn.Conv2d(128,380,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model21.features[8] = nn.Conv2d(380,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "  model22 = copy.deepcopy(model) \n",
        "  model22.features[6] = nn.Conv2d(128,200,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model22.features[8] = nn.Conv2d(200,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "  model23 = copy.deepcopy(model) \n",
        "  model23.features[6] = nn.Conv2d(128,210, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model23.features[8] = nn.Conv2d(210,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "  model24 = copy.deepcopy(model) \n",
        "  model24.features[6] = nn.Conv2d(128,250, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model24.features[8] = nn.Conv2d(250,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "  model25 = copy.deepcopy(model) \n",
        "  model25.features[6] = nn.Conv2d(128,220,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model25.features[8] = nn.Conv2d(220,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "\n",
        "\n",
        "  model26 = copy.deepcopy(model)\n",
        "  model26.features[0] = nn.Conv2d(3 , 100,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model26.features[3] = nn.Conv2d(100,150,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model26.features[6] = nn.Conv2d(150,200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model26.features[8] = nn.Conv2d(200,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model26.features[11] = nn.Conv2d(256,280,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model26.features[13] = nn.Conv2d(280,300, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model26.features[16] = nn.Conv2d(300,350, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model26.features[18] = nn.Conv2d(350,512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "\n",
        "\n",
        "  model27 = copy.deepcopy(model)\n",
        "  model27.features[0] = nn.Conv2d(3 , 90,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model27.features[3] = nn.Conv2d(90,120,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model27.features[6] = nn.Conv2d(120,210, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model27.features[8] = nn.Conv2d(210,260,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model27.features[11] = nn.Conv2d(260,300,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model27.features[13] = nn.Conv2d(300,320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model27.features[16] = nn.Conv2d(320,380, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model27.features[18] = nn.Conv2d(380,512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "\n",
        "  model28 = copy.deepcopy(model)\n",
        "  model28.features[0] = nn.Conv2d(3 , 65,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model28.features[3] = nn.Conv2d(65,150,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model28.features[6] = nn.Conv2d(150,180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model28.features[8] = nn.Conv2d(180,210,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model28.features[11] = nn.Conv2d(210,250,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model28.features[13] = nn.Conv2d(250,290, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model28.features[16] = nn.Conv2d(290,400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model28.features[18] = nn.Conv2d(400,512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "  model29 = copy.deepcopy(model) \n",
        "  model29.features[11] = nn.Conv2d(256,300,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model29.features[13] = nn.Conv2d(300,512,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  \n",
        "\n",
        "  model30 = copy.deepcopy(model) \n",
        "  model30.features[11] = nn.Conv2d(256,280,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model30.features[13] = nn.Conv2d(280,512,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "  \n",
        "\n",
        "  return [model1 , model2 , model3, model3 , model4, model5 ,model6, model7 , model8 , model9 , model10 , model11, model12 ,model13 , model14 , model15, model16 ,model17 , model18 , model19 , model20 , model21, model22, model23 ,model24 , model25 , model26 , model27 , model28 , model29 , model30]\n",
        "\n"
      ],
      "metadata": {
        "id": "g3vh0Og_8yF7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet_modified():\n",
        "  model =  torchvision.models.resnet18(pretrained=True)\n",
        "  model1 = copy.deepcopy(model)\n",
        "  model1.layer1[0].conv1 = nn.Conv2d(64,128 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model1.layer1[0].bn1 = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  model1.layer1[0].conv2 = nn.Conv2d(128 ,64 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "  model2 = copy.deepcopy(model)\n",
        "  model2.layer1[0].conv1 = nn.Conv2d(64,100 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model2.layer1[0].bn1 = nn.BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  model2.layer1[0].conv2 = nn.Conv2d(100 ,64 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "  model3 = copy.deepcopy(model)\n",
        "  model3.layer1[0].conv1 = nn.Conv2d(64,110 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model3.layer1[0].bn1 = nn.BatchNorm2d(110, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  model3.layer1[0].conv2 = nn.Conv2d(110 ,64 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "  model4 = copy.deepcopy(model)\n",
        "  model4.layer1[0].conv1 = nn.Conv2d(64,180 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model4.layer1[0].bn1 = nn.BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  model4.layer1[0].conv2 = nn.Conv2d(180 ,64 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "  model5 = copy.deepcopy(model)\n",
        "  model5.layer1[0].conv1 = nn.Conv2d(64,140 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model5.layer1[0].bn1 = nn.BatchNorm2d(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  model5.layer1[0].conv2 = nn.Conv2d(140 ,64 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "  model6 = copy.deepcopy(model)\n",
        "  model6.layer1[1].conv1 = nn.Conv2d(64,120 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model6.layer1[1].bn1 = nn.BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  model6.layer1[1].conv2 = nn.Conv2d(120 ,64 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "  model7 = copy.deepcopy(model)\n",
        "  model7.layer1[1].conv1 = nn.Conv2d(64,130 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model7.layer1[1].bn1 = nn.BatchNorm2d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  model7.layer1[1].conv2 = nn.Conv2d(130 ,64 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "  model8 = copy.deepcopy(model)\n",
        "  model8.layer1[1].conv1 = nn.Conv2d(64,100 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model8.layer1[1].bn1 = nn.BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  model8.layer1[1].conv2 = nn.Conv2d(100 ,64 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "  model9 = copy.deepcopy(model)\n",
        "  model9.layer1[1].conv1 = nn.Conv2d(64,150 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model9.layer1[1].bn1 = nn.BatchNorm2d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  model9.layer1[1].conv2 = nn.Conv2d(150 ,64 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "  model10 = copy.deepcopy(model)\n",
        "  model10.layer1[1].conv1 = nn.Conv2d(64,200 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model10.layer1[1].bn1 = nn.BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  model10.layer1[1].conv2 = nn.Conv2d(200 ,64 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "  model11 = copy.deepcopy(model)\n",
        "  model11.layer1[1].conv1 = nn.Conv2d(64,90 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model11.layer1[1].bn1 = nn.BatchNorm2d(90, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  model11.layer1[1].conv2 = nn.Conv2d(90 ,64 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "\n",
        "\n",
        "  model12 = copy.deepcopy(model)\n",
        "  model12.layer2[0].conv1 = nn.Conv2d(64, 100, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
        "  model12.layer2[0].bn1 = nn.BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  model12.layer2[0].conv2 = nn.Conv2d(100 ,64 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "  model13 = copy.deepcopy(model)\n",
        "  model13.layer2[0].conv1 = nn.Conv2d(64, 80 ,  kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
        "  model13.layer2[0].bn1 = nn.BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  model13.layer2[0].conv2 = nn.Conv2d(80 ,64 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "\n",
        "  model11 = copy.deepcopy(model)\n",
        "  model11.layer2[1].conv1 = nn.Conv2d(64,90 ,  kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
        "  model11.layer2[1].bn1 = nn.BatchNorm2d(90, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  model11.layer2[1].conv2 = nn.Conv2d(90 ,64 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  \n",
        "\n",
        "\n",
        "  model12 = copy.deepcopy(model)\n",
        "  model12.layer4[0].conv1 = nn.Conv2d(256, 400, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
        "  model12.layer4[0].bn1 = nn.BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  model12.layer4[0].conv2 = nn.Conv2d(400, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "\n",
        "\n",
        "  model13 = copy.deepcopy(model)\n",
        "  model13.layer4[0].conv1 = nn.Conv2d(256, 300, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
        "  model13.layer4[0].bn1 = nn.BatchNorm2d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  model13.layer4[0].conv2 = nn.Conv2d(300, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "\n",
        "\n",
        "  model14 = copy.deepcopy(model)\n",
        "  model14.layer4[0].conv1 = nn.Conv2d(256, 500, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
        "  model14.layer4[0].bn1 = nn.BatchNorm2d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  model14.layer4[0].conv2 = nn.Conv2d(500, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "\n",
        "  return [model1, model2 , model3 , model4 , model5 , model6 , model7, model8, model9 , model10, model11,model12,model13 , model14]"
      ],
      "metadata": {
        "id": "1XOiW5j0TRMC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total =101\n"
      ],
      "metadata": {
        "id": "1P3xvXLEoLmW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_hardware_latency():\n",
        "  alexnet = torchvision.models.alexnet(pretrained=True)\n",
        "  vgg11 = torchvision.models.vgg11(pretrained=True)\n",
        "  vgg11_bn = torchvision.models.vgg11_bn(pretrained=True)\n",
        "  vgg13 = torchvision.models.vgg13(pretrained=True)\n",
        "  vgg13_bn = torchvision.models.vgg13_bn(pretrained=True)\n",
        "  vgg16 = torchvision.models.vgg16(pretrained=True)\n",
        "  vgg16_bn = torchvision.models.vgg16_bn(pretrained=True)\n",
        "  vgg19 = torchvision.models.vgg19(pretrained=True)\n",
        "  vgg19_bn = torchvision.models.vgg19_bn(pretrained=True)\n",
        "  resnet18 = torchvision.models.resnet18(pretrained=True)\n",
        "  resnet34 = torchvision.models.resnet34(pretrained=True)\n",
        "  resnet50 = torchvision.models.resnet50(pretrained=True)\n",
        "  resnet101 = torchvision.models.resnet101(pretrained=True)\n",
        "  resnet152 = torchvision.models.resnet152(pretrained=True)\n",
        "  densenet121 = torchvision.models.densenet121(pretrained=True)\n",
        "  densenet169 = torchvision.models.densenet169(pretrained=True)\n",
        "  densenet161 = torchvision.models.densenet161(pretrained=True)\n",
        "  densenet201 = torchvision.models.densenet201(pretrained=True)\n",
        "  googlenet = torchvision.models.googlenet(pretrained=True)\n",
        "  wide_resnet50_2= torchvision.models.wide_resnet50_2(pretrained=True)\n",
        "  wide_resnet101_2 = torchvision.models.wide_resnet101_2(pretrained=True)\n",
        "\n",
        "\n",
        "  models = [alexnet ,vgg11 , vgg11_bn ,vgg13 , vgg13_bn , vgg16 , vgg16_bn , vgg19 , vgg19_bn , resnet18 , resnet34 , resnet50 , resnet101 , resnet152 , densenet121 , densenet169 , densenet161 , densenet201 , googlenet ,wide_resnet50_2 , wide_resnet101_2 ]\n",
        "  models.extend(alexnet_modified())\n",
        "  models.extend(vgg_modified())\n",
        "  models.extend(resnet_modified())  \n",
        "  print(len(models))\n",
        " "
      ],
      "metadata": {
        "id": "lsR9h58MoZcl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_hardware_latency()"
      ],
      "metadata": {
        "id": "EM7LUNd5q4fS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dgdspR8Dq6SM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}