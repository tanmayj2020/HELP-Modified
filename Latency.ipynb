{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Latency.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMfdiaD2jATEpz8XhESCwX2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanmayj2020/HELP-Modified/blob/master/Latency.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTecPFscYSCv",
        "outputId": "5824f120-b5d6-4088-a0f2-2c3fd55cdf63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SINGLE ARCHITECTURE - SINGLE HARDWARE"
      ],
      "metadata": {
        "id": "8r8PPsvQZGZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time \n",
        "import torch\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torch import nn\n",
        "import copy "
      ],
      "metadata": {
        "id": "enGLhU5bdFPt"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_latency_gpu(model , dummy_input):\n",
        "  device = torch.device(\"cuda\")\n",
        "  model.to(device)\n",
        "  dummy_input = dummy_input.to(device)\n",
        "  starter , ender = torch.cuda.Event(enable_timing = True) , torch.cuda.Event(enable_timing=True)\n",
        "  repetitions = 300\n",
        "  timings =np.zeros((repetitions , 1))\n",
        "  #GPU WARM UP \n",
        "  for _ in range(10):\n",
        "    _ = model(dummy_input)\n",
        "  #MEASURE LATENCY \n",
        "  with torch.no_grad():\n",
        "    for rep in range(repetitions):\n",
        "      starter.record()\n",
        "      _ = model(dummy_input) \n",
        "      ender.record()\n",
        "      #WAIT for GPU sync \n",
        "      torch.cuda.synchronize()\n",
        "      curr_time = starter.elapsed_time(ender)\n",
        "      timings[rep] = curr_time\n",
        "  mean_syn = np.sum(timings)/repetitions\n",
        "  std_syn = np.std(timings)\n",
        "  return mean_syn , std_syn\n",
        "  \n",
        "def calculate_latency_cpu(model , dummy_input):\n",
        "  repetitions = 2\n",
        "  timings= np.zeros((repetitions , 1))\n",
        "  #WARM UP \n",
        "  #for _ in range(10):\n",
        "   # _ = model(dummy_input)\n",
        "  #MEASURE LATENCY \n",
        "  with torch.no_grad():\n",
        "    for rep in range(repetitions):\n",
        "      start_time = time.time()\n",
        "      _ = model(dummy_input) \n",
        "      end_time = time.time()\n",
        "      curr_time = end_time -start_time\n",
        "      timings[rep] = curr_time\n",
        "  mean_syn = np.sum(timings)/repetitions\n",
        "  std_syn = np.std(timings)\n",
        "  return mean_syn , std_syn\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "dVmNoEakZNL7"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_input():\n",
        "  torch.manual_seed(1)\n",
        "  dummy_input = torch.randn(1 , 3 , 224 , 224 , dtype=torch.float)\n",
        "  return dummy_input"
      ],
      "metadata": {
        "id": "Fpmqf42Nc49j"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def alexnet1():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model1 = copy.deepcopy(model) \n",
        "  model1.features[3] = nn.Conv2d(64,100, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model1.features[6] = nn.Conv2d(100,384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model1\n",
        "\n",
        "def alexnet2():\n",
        "  model  = torchvision.models.alexnet(pretrained=True) \n",
        "  model2 = copy.deepcopy(model) \n",
        "  model2.features[3] = nn.Conv2d(64,90, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model2.features[6] = nn.Conv2d(90,384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model2\n",
        "\n",
        "def alexnet3():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model2 = copy.deepcopy(model) \n",
        "  model2.features[3] = nn.Conv2d(64,80, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model2.features[6] = nn.Conv2d(80,384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model2\n",
        "\n",
        "def alexnet4():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model3 = copy.deepcopy(model) \n",
        "  model3.features[3] = nn.Conv2d(64,70, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model3.features[6] = nn.Conv2d(70,384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model3\n",
        "\n",
        "def alexnet5():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model4 = copy.deepcopy(model) \n",
        "  model4.features[3] = nn.Conv2d(64,105, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model4.features[6] = nn.Conv2d(105,384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model4\n",
        "\n",
        "def alexnet6():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model5 = copy.deepcopy(model) \n",
        "  model5.features[3] = nn.Conv2d(64,120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model5.features[6] = nn.Conv2d(120,384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model5\n",
        "  \n",
        "def alexnet7():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model6 = copy.deepcopy(model) \n",
        "  model6.features[3] = nn.Conv2d(64,130, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model6.features[6] = nn.Conv2d(130,384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model6\n",
        "  \n",
        "def alexnet8():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model7 = copy.deepcopy(model) \n",
        "  model7.features[3] = nn.Conv2d(64,140, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model7.features[6] = nn.Conv2d(140,384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model7\n",
        "  \n",
        "def alexnet9():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)  \n",
        "  model8 = copy.deepcopy(model) \n",
        "  model8.features[3] = nn.Conv2d(64,145, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model8.features[6] = nn.Conv2d(145,384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model8\n",
        "  \n",
        "def alexnet10():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model9 = copy.deepcopy(model) \n",
        "  model9.features[3] = nn.Conv2d(64,160, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model9.features[6] = nn.Conv2d(160,384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model9\n",
        "  \n",
        "def alexnet11():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)  \n",
        "  model10 = copy.deepcopy(model) \n",
        "  model10.features[3] = nn.Conv2d(64,170, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model10.features[6] = nn.Conv2d(170,384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model10\n",
        "  \n",
        "def alexnet12():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model11 = copy.deepcopy(model) \n",
        "  model11.features[3] = nn.Conv2d(64,150, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model11.features[6] = nn.Conv2d(150,384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model11\n",
        "  \n",
        "def alexnet13():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)  \n",
        "  model12 = copy.deepcopy(model) \n",
        "  model12.features[3] = nn.Conv2d(64,180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model12.features[6] = nn.Conv2d(180,384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model12\n",
        "  \n",
        "def alexnet14():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model13 = copy.deepcopy(model) \n",
        "  model13.features[6] = nn.Conv2d(192,300, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model13.features[8] = nn.Conv2d(300,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model13\n",
        "  \n",
        "def alexnet15():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model14 = copy.deepcopy(model) \n",
        "  model14.features[6] = nn.Conv2d(192,310, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model14.features[8] = nn.Conv2d(310,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model14\n",
        "  \n",
        "def alexnet16():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model15 = copy.deepcopy(model) \n",
        "  model15.features[6] = nn.Conv2d(192,320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model15.features[8] = nn.Conv2d(320,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model15\n",
        "  \n",
        "def alexnet17():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model16 = copy.deepcopy(model) \n",
        "  model16.features[6] = nn.Conv2d(192,330, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model16.features[8] = nn.Conv2d(330,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model16\n",
        "  \n",
        "def alexnet18():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model17 = copy.deepcopy(model) \n",
        "  model17.features[6] = nn.Conv2d(192,340, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model17.features[8] = nn.Conv2d(340,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model17\n",
        "  \n",
        "def alexnet19():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model18 = copy.deepcopy(model) \n",
        "  model18.features[6] = nn.Conv2d(192,350, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model18.features[8] = nn.Conv2d(350,256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
        "  return model18\n",
        "  \n",
        "def alexnet20():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model19 = copy.deepcopy(model) \n",
        "  model19.features[6] = nn.Conv2d(192,360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model19.features[8] = nn.Conv2d(360,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model19\n",
        "  \n",
        "def alexnet21():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model20 = copy.deepcopy(model) \n",
        "  model20.features[6] = nn.Conv2d(192,370, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model20.features[8] = nn.Conv2d(370,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model20\n",
        "  \n",
        "def alexnet22():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model21 = copy.deepcopy(model) \n",
        "  model21.features[6] = nn.Conv2d(192,380, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model21.features[8] = nn.Conv2d(380,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model21\n",
        "  \n",
        "def alexnet23():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model22 = copy.deepcopy(model) \n",
        "  model22.features[6] = nn.Conv2d(192,200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model22.features[8] = nn.Conv2d(200,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model22\n",
        "  \n",
        "def alexnet24():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model23 = copy.deepcopy(model) \n",
        "  model23.features[6] = nn.Conv2d(192,210, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model23.features[8] = nn.Conv2d(210,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model23\n",
        "  \n",
        "def alexnet25():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model24 = copy.deepcopy(model) \n",
        "  model24.features[6] = nn.Conv2d(192,250, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model24.features[8] = nn.Conv2d(250,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model24\n",
        "  \n",
        "def alexnet26():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model25 = copy.deepcopy(model) \n",
        "  model25.features[6] = nn.Conv2d(192,220, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model25.features[8] = nn.Conv2d(220,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model25\n",
        "  \n",
        "def alexnet27():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model26 = copy.deepcopy(model)\n",
        "  model26.features[0] = nn.Conv2d(3 , 100, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
        "  model26.features[3] = nn.Conv2d(100,150, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model26.features[6] = nn.Conv2d(150,200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model26.features[8] = nn.Conv2d(200,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model26\n",
        "  \n",
        "def alexnet28():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model27 = copy.deepcopy(model) \n",
        "  model27.features[0] = nn.Conv2d(3,90, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
        "  model27.features[3] = nn.Conv2d(90,150, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model27.features[6] = nn.Conv2d(150,240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model27.features[8] = nn.Conv2d(240,256,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model27\n",
        "  \n",
        "def alexnet29():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model28 = copy.deepcopy(model) \n",
        "  model28.features[0] = nn.Conv2d(3,200, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
        "  model28.features[3] = nn.Conv2d(200,220, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model28.features[6] = nn.Conv2d(220,290,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model28.features[8] = nn.Conv2d(290,256,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model28\n",
        "  \n",
        "def alexnet30():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model29 = copy.deepcopy(model) \n",
        "  model29.features[0] = nn.Conv2d(3,180,kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
        "  model29.features[3] = nn.Conv2d(180,360, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model29.features[6] = nn.Conv2d(360,420, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model29.features[8] = nn.Conv2d(420,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model29\n",
        "  \n",
        "def alexnet31():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model30 = copy.deepcopy(model) \n",
        "  model30.features[0] = nn.Conv2d(3,70, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
        "  model30.features[3] = nn.Conv2d(70,150, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model30.features[6] = nn.Conv2d(150,210, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model30.features[8] = nn.Conv2d(210,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model30\n",
        "  \n",
        "def alexnet32():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model31 = copy.deepcopy(model) \n",
        "  model31.features[0] = nn.Conv2d(3,110, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
        "  model31.features[3] = nn.Conv2d(110,200, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model31.features[6] = nn.Conv2d(200,192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model31.features[8] = nn.Conv2d(192,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model31\n",
        "  \n",
        "def alexnet33():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model32 = copy.deepcopy(model) \n",
        "  model32.features[0] = nn.Conv2d(3,100,kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
        "  model32.features[3] = nn.Conv2d(100,150, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model32.features[6] = nn.Conv2d(150,300,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model32.features[8] = nn.Conv2d(300,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model32\n",
        "  \n",
        "def alexnet34():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model33 = copy.deepcopy(model) \n",
        "  model33.features[0] = nn.Conv2d(3,80, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
        "  model33.features[3] = nn.Conv2d(80,150, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model33.features[6] = nn.Conv2d(150,200,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model33.features[8] = nn.Conv2d(200,256,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model33\n",
        "  \n",
        "def alexnet35():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model34 = copy.deepcopy(model) \n",
        "  model34.features[0] = nn.Conv2d(3,150, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
        "  model34.features[3] = nn.Conv2d(150,230, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model34.features[6] = nn.Conv2d(230,395,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model34.features[8] = nn.Conv2d(395,256,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model34\n",
        "  \n",
        "def alexnet36():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model35 = copy.deepcopy(model) \n",
        "  model35.features[0] = nn.Conv2d(3,160, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
        "  model35.features[3] = nn.Conv2d(160 ,195, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model35.features[6] = nn.Conv2d(195,240,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model35.features[8] = nn.Conv2d(240,256,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model35\n",
        "  \n",
        "def alexnet37():\n",
        "  model  = torchvision.models.alexnet(pretrained=True)\n",
        "  model36 = copy.deepcopy(model) \n",
        "  model36.features[0] = nn.Conv2d(3,190, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
        "  model36.features[3] = nn.Conv2d(190,210, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "  model36.features[6] = nn.Conv2d(210,280,kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model36.features[8] = nn.Conv2d(280,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model36\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "W9JJqO0Azqhq"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vgg1():\n",
        "  model  = torchvision.models.vgg11(pretrained=True)\n",
        "  model1 = copy.deepcopy(model) \n",
        "  model1.features[3] = nn.Conv2d(64,150,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model1.features[6] = nn.Conv2d(150,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model1\n",
        "\n",
        "def vgg2():\n",
        "  model  = torchvision.models.vgg11(pretrained=True)  \n",
        "  model2 = copy.deepcopy(model) \n",
        "  model2.features[3] = nn.Conv2d(64,180,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model2.features[6] = nn.Conv2d(180,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model2\n",
        "  \n",
        "def vgg3():\n",
        "  model  = torchvision.models.vgg11(pretrained=True) \n",
        "  model2 = copy.deepcopy(model) \n",
        "  model2.features[3] = nn.Conv2d(64,80,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model2.features[6] = nn.Conv2d(80,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model2\n",
        "  \n",
        "def vgg4():\n",
        "  model  = torchvision.models.vgg11(pretrained=True)\n",
        "  model3 = copy.deepcopy(model) \n",
        "  model3.features[3] = nn.Conv2d(64,70, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model3.features[6] = nn.Conv2d(70,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model3\n",
        "  \n",
        "def vgg5():\n",
        "  model  = torchvision.models.vgg11(pretrained=True)\n",
        "  model4 = copy.deepcopy(model) \n",
        "  model4.features[3] = nn.Conv2d(64,105,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model4.features[6] = nn.Conv2d(105,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model4\n",
        "  \n",
        "def vgg6():\n",
        "  model  = torchvision.models.vgg11(pretrained=True)\n",
        "  model5 = copy.deepcopy(model) \n",
        "  model5.features[3] = nn.Conv2d(64,120,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model5.features[6] = nn.Conv2d(120,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model5\n",
        "\n",
        "def vgg7():\n",
        "  model  = torchvision.models.vgg11(pretrained=True)\n",
        "  model6 = copy.deepcopy(model) \n",
        "  model6.features[3] = nn.Conv2d(64,130, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model6.features[6] = nn.Conv2d(130,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model6\n",
        "  \n",
        "def vgg8():\n",
        "  model  = torchvision.models.vgg11(pretrained=True)\n",
        "  model7 = copy.deepcopy(model) \n",
        "  model7.features[3] = nn.Conv2d(64,140, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model7.features[6] = nn.Conv2d(140,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model7\n",
        "  \n",
        "def vgg9():\n",
        "  model  = torchvision.models.vgg11(pretrained=True)\n",
        "  model8 = copy.deepcopy(model) \n",
        "  model8.features[3] = nn.Conv2d(64,145, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model8.features[6] = nn.Conv2d(145,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model8\n",
        "  \n",
        "def vgg10():\n",
        "  model  = torchvision.models.vgg11(pretrained=True)\n",
        "  model9 = copy.deepcopy(model) \n",
        "  model9.features[3] = nn.Conv2d(64,160,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model9.features[6] = nn.Conv2d(160,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model9\n",
        "  \n",
        "def vgg11():\n",
        "  model  = torchvision.models.vgg11(pretrained=True)\n",
        "  model10 = copy.deepcopy(model) \n",
        "  model10.features[3] = nn.Conv2d(64,170,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model10.features[6] = nn.Conv2d(170,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model10\n",
        "  \n",
        "def vgg12():\n",
        "  model  = torchvision.models.vgg11(pretrained=True)  \n",
        "  model11 = copy.deepcopy(model) \n",
        "  model11.features[3] = nn.Conv2d(64,150,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model11.features[6] = nn.Conv2d(150,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model11\n",
        "  \n",
        "def vgg13():\n",
        "  model  = torchvision.models.vgg11(pretrained=True)  \n",
        "  model12 = copy.deepcopy(model) \n",
        "  model12.features[3] = nn.Conv2d(64,180,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model12.features[6] = nn.Conv2d(180,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model12\n",
        "  \n",
        "\n",
        "def vgg14():\n",
        "  model  = torchvision.models.vgg11(pretrained=True)\n",
        "  model13 = copy.deepcopy(model) \n",
        "  model13.features[6] = nn.Conv2d(128,300,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model13.features[8] = nn.Conv2d(300,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model13\n",
        "  \n",
        "def vgg15():\n",
        "  model  = torchvision.models.vgg11(pretrained=True)\n",
        "  model14 = copy.deepcopy(model) \n",
        "  model14.features[6] = nn.Conv2d(128,310,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model14.features[8] = nn.Conv2d(310,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model14\n",
        "  \n",
        "def vgg16():\n",
        "  model  = torchvision.models.vgg11(pretrained=True)\n",
        "  model15 = copy.deepcopy(model) \n",
        "  model15.features[6] = nn.Conv2d(128,320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model15.features[8] = nn.Conv2d(320,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model15\n",
        "  \n",
        "def vgg17():\n",
        "  model  = torchvision.models.vgg11(pretrained=True)\n",
        "  model16 = copy.deepcopy(model) \n",
        "  model16.features[6] = nn.Conv2d(128,330,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model16.features[8] = nn.Conv2d(330,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model16\n",
        "  \n",
        "def vgg18():\n",
        "  model  = torchvision.models.vgg11(pretrained=True)\n",
        "  model17 = copy.deepcopy(model) \n",
        "  model17.features[6] = nn.Conv2d(128,340, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model17.features[8] = nn.Conv2d(340,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model17\n",
        "  \n",
        "def vgg19():\n",
        "  model  = torchvision.models.vgg11(pretrained=True)\n",
        "  model18 = copy.deepcopy(model) \n",
        "  model18.features[6] = nn.Conv2d(128,350,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model18.features[8] = nn.Conv2d(350,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model18\n",
        "  \n",
        "def vgg20():\n",
        "  model  = torchvision.models.vgg11(pretrained=True)\n",
        "  model19 = copy.deepcopy(model) \n",
        "  model19.features[6] = nn.Conv2d(128,360,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model19.features[8] = nn.Conv2d(360,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model19\n",
        "  \n",
        "def vgg21():\n",
        "  model  = torchvision.models.vgg11(pretrained=True)\n",
        "  model20 = copy.deepcopy(model) \n",
        "  model20.features[6] = nn.Conv2d(128,370,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model20.features[8] = nn.Conv2d(370,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model20\n",
        "  \n",
        "def vgg22():\n",
        "  model  = torchvision.models.vgg11(pretrained=True)\n",
        "  model21 = copy.deepcopy(model) \n",
        "  model21.features[6] = nn.Conv2d(128,380,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model21.features[8] = nn.Conv2d(380,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model21\n",
        "  \n",
        "def vgg23():\n",
        "  model  = torchvision.models.vgg11(pretrained=True)\n",
        "  model22 = copy.deepcopy(model) \n",
        "  model22.features[6] = nn.Conv2d(128,200,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model22.features[8] = nn.Conv2d(200,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model22\n",
        "  \n",
        "def vgg24():\n",
        "  model  = torchvision.models.vgg11(pretrained=True)\n",
        "  model23 = copy.deepcopy(model) \n",
        "  model23.features[6] = nn.Conv2d(128,210, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model23.features[8] = nn.Conv2d(210,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model23\n",
        "  \n",
        "def vgg25():\n",
        "  model  = torchvision.models.vgg11(pretrained=True)\n",
        "  model24 = copy.deepcopy(model) \n",
        "  model24.features[6] = nn.Conv2d(128,250, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model24.features[8] = nn.Conv2d(250,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model24\n",
        "  \n",
        "def vgg26():\n",
        "  model  = torchvision.models.vgg11(pretrained=True)\n",
        "  model25 = copy.deepcopy(model) \n",
        "  model25.features[6] = nn.Conv2d(128,220,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model25.features[8] = nn.Conv2d(220,256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model25  \n",
        "\n",
        "def vgg27():\n",
        "  model  = torchvision.models.vgg11(pretrained=True)\n",
        "  model26 = copy.deepcopy(model)\n",
        "  model26.features[0] = nn.Conv2d(3 , 100,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model26.features[3] = nn.Conv2d(100,150,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model26.features[6] = nn.Conv2d(150,200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model26.features[8] = nn.Conv2d(200,256,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model26.features[11] = nn.Conv2d(256,280,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model26.features[13] = nn.Conv2d(280,300, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model26.features[16] = nn.Conv2d(300,350, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model26.features[18] = nn.Conv2d(350,512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model26  \n",
        "\n",
        "def vgg28():\n",
        "  model  = torchvision.models.vgg11(pretrained=True)\n",
        "  model27 = copy.deepcopy(model)\n",
        "  model27.features[0] = nn.Conv2d(3 , 90,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model27.features[3] = nn.Conv2d(90,120,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model27.features[6] = nn.Conv2d(120,210, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model27.features[8] = nn.Conv2d(210,260,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model27.features[11] = nn.Conv2d(260,300,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model27.features[13] = nn.Conv2d(300,320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model27.features[16] = nn.Conv2d(320,380, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model27.features[18] = nn.Conv2d(380,512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model27\n",
        "  \n",
        "def vgg29():\n",
        "  model  = torchvision.models.vgg11(pretrained=True)\n",
        "  model28 = copy.deepcopy(model)\n",
        "  model28.features[0] = nn.Conv2d(3 , 65,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model28.features[3] = nn.Conv2d(65,150,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model28.features[6] = nn.Conv2d(150,180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model28.features[8] = nn.Conv2d(180,210,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model28.features[11] = nn.Conv2d(210,250,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model28.features[13] = nn.Conv2d(250,290, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model28.features[16] = nn.Conv2d(290,400, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model28.features[18] = nn.Conv2d(400,512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model28\n",
        "  \n",
        "def vgg30():\n",
        "  model  = torchvision.models.vgg11(pretrained=True)\n",
        "  model29 = copy.deepcopy(model) \n",
        "  model29.features[11] = nn.Conv2d(256,300,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model29.features[13] = nn.Conv2d(300,512,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model29\n",
        "  \n",
        "\n",
        "def vgg31():\n",
        "  model  = torchvision.models.vgg11(pretrained=True)\n",
        "  model30 = copy.deepcopy(model) \n",
        "  model30.features[11] = nn.Conv2d(256,280,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model30.features[13] = nn.Conv2d(280,512,  kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "  return model30\n",
        "  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "g3vh0Og_8yF7"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet1():\n",
        "  model =  torchvision.models.resnet18(pretrained=True)\n",
        "  model1 = copy.deepcopy(model)\n",
        "  model1.layer1[0].conv1 = nn.Conv2d(64,128 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model1.layer1[0].bn1 = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  model1.layer1[0].conv2 = nn.Conv2d(128 ,64 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model1\n",
        "\n",
        "def resnet2():\n",
        "  model =  torchvision.models.resnet18(pretrained=True)\n",
        "  model2 = copy.deepcopy(model)\n",
        "  model2.layer1[0].conv1 = nn.Conv2d(64,100 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model2.layer1[0].bn1 = nn.BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  model2.layer1[0].conv2 = nn.Conv2d(100 ,64 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model2\n",
        "  \n",
        "def resnet3():\n",
        "  model =  torchvision.models.resnet18(pretrained=True)\n",
        "  model3 = copy.deepcopy(model)\n",
        "  model3.layer1[0].conv1 = nn.Conv2d(64,110 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model3.layer1[0].bn1 = nn.BatchNorm2d(110, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  model3.layer1[0].conv2 = nn.Conv2d(110 ,64 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model3\n",
        "  \n",
        "def resnet4():\n",
        "  model =  torchvision.models.resnet18(pretrained=True)\n",
        "  model4 = copy.deepcopy(model)\n",
        "  model4.layer1[0].conv1 = nn.Conv2d(64,180 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model4.layer1[0].bn1 = nn.BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  model4.layer1[0].conv2 = nn.Conv2d(180 ,64 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model4\n",
        "  \n",
        "def resnet5():\n",
        "  model =  torchvision.models.resnet18(pretrained=True)\n",
        "  model5 = copy.deepcopy(model)\n",
        "  model5.layer1[0].conv1 = nn.Conv2d(64,140 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model5.layer1[0].bn1 = nn.BatchNorm2d(140, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  model5.layer1[0].conv2 = nn.Conv2d(140 ,64 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model5\n",
        "  \n",
        "def resnet6():\n",
        "  model =  torchvision.models.resnet18(pretrained=True)\n",
        "  model6 = copy.deepcopy(model)\n",
        "  model6.layer1[1].conv1 = nn.Conv2d(64,120 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model6.layer1[1].bn1 = nn.BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  model6.layer1[1].conv2 = nn.Conv2d(120 ,64 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model6\n",
        "  \n",
        "def resnet7():\n",
        "  model =  torchvision.models.resnet18(pretrained=True)\n",
        "  model7 = copy.deepcopy(model)\n",
        "  model7.layer1[1].conv1 = nn.Conv2d(64,130 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model7.layer1[1].bn1 = nn.BatchNorm2d(130, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  model7.layer1[1].conv2 = nn.Conv2d(130 ,64 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model7\n",
        "  \n",
        "def resnet8():\n",
        "  model =  torchvision.models.resnet18(pretrained=True)\n",
        "  model8 = copy.deepcopy(model)\n",
        "  model8.layer1[1].conv1 = nn.Conv2d(64,100 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model8.layer1[1].bn1 = nn.BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  model8.layer1[1].conv2 = nn.Conv2d(100 ,64 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model8\n",
        "  \n",
        "def resnet9():\n",
        "  model =  torchvision.models.resnet18(pretrained=True)\n",
        "  model9 = copy.deepcopy(model)\n",
        "  model9.layer1[1].conv1 = nn.Conv2d(64,150 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model9.layer1[1].bn1 = nn.BatchNorm2d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  model9.layer1[1].conv2 = nn.Conv2d(150 ,64 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model9\n",
        "  \n",
        "def resnet10():\n",
        "  model =  torchvision.models.resnet18(pretrained=True)\n",
        "  model10 = copy.deepcopy(model)\n",
        "  model10.layer1[1].conv1 = nn.Conv2d(64,200 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model10.layer1[1].bn1 = nn.BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  model10.layer1[1].conv2 = nn.Conv2d(200 ,64 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model10\n",
        "  \n",
        "def resnet11():\n",
        "  model =  torchvision.models.resnet18(pretrained=True)\n",
        "  model11 = copy.deepcopy(model)\n",
        "  model11.layer1[1].conv1 = nn.Conv2d(64,90 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  model11.layer1[1].bn1 = nn.BatchNorm2d(90, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  model11.layer1[1].conv2 = nn.Conv2d(90 ,64 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model11\n",
        "  \n",
        "\n",
        "def resnet12():\n",
        "  model =  torchvision.models.resnet18(pretrained=True)\n",
        "  model12 = copy.deepcopy(model)\n",
        "  model12.layer2[0].conv1 = nn.Conv2d(64, 100, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
        "  model12.layer2[0].bn1 = nn.BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  model12.layer2[0].conv2 = nn.Conv2d(100 ,128 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model12\n",
        "  \n",
        "def resnet13():\n",
        "  model =  torchvision.models.resnet18(pretrained=True)\n",
        "  model13 = copy.deepcopy(model)\n",
        "  model13.layer2[0].conv1 = nn.Conv2d(64, 80 ,  kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
        "  model13.layer2[0].bn1 = nn.BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  model13.layer2[0].conv2 = nn.Conv2d(80 ,128 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model13\n",
        "  \n",
        "\n",
        "def resnet14():\n",
        "  model =  torchvision.models.resnet18(pretrained=True)\n",
        "  model11 = copy.deepcopy(model)\n",
        "  model11.layer2[0].conv1 = nn.Conv2d(64,300 ,  kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
        "  model11.layer2[0].bn1 = nn.BatchNorm2d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  model11.layer2[0].conv2 = nn.Conv2d(300 ,128 , kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "  return model11\n",
        "   \n",
        "\n",
        "def resnet15():\n",
        "  model =  torchvision.models.resnet18(pretrained=True)\n",
        "  model12 = copy.deepcopy(model)\n",
        "  model12.layer4[0].conv1 = nn.Conv2d(256, 400, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
        "  model12.layer4[0].bn1 = nn.BatchNorm2d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  model12.layer4[0].conv2 = nn.Conv2d(400, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "  return model12\n",
        "  \n",
        "def resnet16():\n",
        "  model =  torchvision.models.resnet18(pretrained=True)\n",
        "  model13 = copy.deepcopy(model)\n",
        "  model13.layer4[0].conv1 = nn.Conv2d(256, 300, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
        "  model13.layer4[0].bn1 = nn.BatchNorm2d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  model13.layer4[0].conv2 = nn.Conv2d(300, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "  return model13\n",
        "  \n",
        "\n",
        "def resnet17():\n",
        "  model =  torchvision.models.resnet18(pretrained=True)\n",
        "  model14 = copy.deepcopy(model)\n",
        "  model14.layer4[0].conv1 = nn.Conv2d(256, 500, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
        "  model14.layer4[0].bn1 = nn.BatchNorm2d(500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "  model14.layer4[0].conv2 = nn.Conv2d(500, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
        "  return model14\n",
        "  \n"
      ],
      "metadata": {
        "id": "1XOiW5j0TRMC"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def alexnet():\n",
        "  return torchvision.models.alexnet(pretrained=True)\n",
        "\n",
        "def vg11():\n",
        "  return torchvision.models.vgg11(pretrained=True)\n",
        "\n",
        "def vgg11_bn():\n",
        "  return torchvision.models.vgg11_bn(pretrained=True)\n",
        "\n",
        "def vgg13():\n",
        "  return torchvision.models.vgg13(pretrained=True)\n",
        "\n",
        "def vgg13_bn():\n",
        "  return torchvision.models.vgg13_bn(pretrained=True)\n",
        "\n",
        "def vgg16():\n",
        "  return torchvision.models.vgg16(pretrained=True)\n",
        "\n",
        "def vgg16_bn():\n",
        "  return torchvision.models.vgg16_bn(pretrained=True)\n",
        "\n",
        "def vgg19():\n",
        "  return torchvision.models.vgg19(pretrained=True)\n",
        "\n",
        "def vgg19_bn():\n",
        "  return torchvision.models.vgg19_bn(pretrained=True)\n",
        "\n",
        "def resnet18():\n",
        "  return torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "def resnet34():\n",
        "  return torchvision.models.resnet34(pretrained=True)\n",
        "\n",
        "def resnet50():\n",
        "  return torchvision.models.resnet50(pretrained=True)\n",
        "\n",
        "def resnet101():\n",
        "  return torchvision.models.resnet101(pretrained=True)\n",
        "\n",
        "def resnet152():\n",
        "  return torchvision.models.resnet152(pretrained=True)\n",
        "\n",
        "def densenet121():\n",
        "  return torchvision.models.densenet121(pretrained=True)\n",
        "\n",
        "def densenet169():\n",
        "  return torchvision.models.densenet169(pretrained=True)\n",
        "\n",
        "def densenet161():\n",
        "  return torchvision.models.densenet161(pretrained=True)\n",
        "\n",
        "def densenet201():\n",
        "  return torchvision.models.densenet201(pretrained=True)\n",
        "\n",
        "def googlenet():\n",
        "  return torchvision.models.googlenet(pretrained=True)\n",
        "\n",
        "def wide_resnet50_2():\n",
        "  return torchvision.models.wide_resnet50_2(pretrained=True)\n",
        "\n",
        "def wide_resnet101_2():\n",
        "  return torchvision.models.wide_resnet101_2(pretrained=True)\n"
      ],
      "metadata": {
        "id": "1P3xvXLEoLmW"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_hardware_latency(hardware_name , hardware_info , if_hardware_is_cuda):\n",
        "  models = [\"alexnet\" ,\"vgg11\" , \"vgg11_bn\" ,\"vgg13\", \"vgg13_bn\" , \"vgg16\" , \"vgg16_bn\" , \"vgg19\" , \"vgg19_bn\" , \"resnet18\" , \"resnet34\" , \"resnet50\" , \"resnet101\" , \"resnet152\" , \"densenet121\" , \"densenet169\" , \"densenet161\" , \"densenet201\" , \"googlenet\" ,\"wide_resnet50_2\" , \"wide_resnet101_2\"]\n",
        "  for i in range(1 , 38):\n",
        "    models.append(\"alexnet{}\".format(i))\n",
        "  for i in range(1 , 32):\n",
        "    models.append(\"vgg{}\".format(i))\n",
        "  for i in range(1 , 18):\n",
        "    models.append(\"resnet{}\".format(i))\n",
        "\n",
        "  latency_list = []\n",
        "  std_dev_list = []\n",
        "  for model_string in models:\n",
        "    model = eval(model_string + \"()\")\n",
        "    print(\"Loaded {}\".format(model_string))\n",
        "    dummy_input = generate_input()\n",
        "    print(\"Calculating latency for {}\".format(model_string))\n",
        "    if if_hardware_is_cuda:\n",
        "      latency_model , std_dev = calculate_latency_gpu(model , dummy_input)\n",
        "    else:\n",
        "      latency_model , std_dev = calculate_latency_cpu(model , dummy_input)\n",
        "      \n",
        "    latency_list.append(latency_model)\n",
        "    std_dev_list.append(std_dev)\n",
        "  \n",
        "  hardware_dict = {}\n",
        "  hardware_dict[\"name\"] = hardware_name\n",
        "  hardware_dict[\"hardware_info\"] = hardware_info \n",
        "  hardware_dict[\"latency\"] = latency_list\n",
        "  hardware_dict[\"std_dev_latency\"] = std_dev_list\n",
        "  torch.save(hardware_dict , hardware_name+\".pt\")\n",
        "\n",
        "  print(\"Calculated hardware latency\")\n",
        "  \n",
        "\n",
        "\n",
        "  \n",
        "  \n",
        "  "
      ],
      "metadata": {
        "id": "lsR9h58MoZcl"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_hardware_latency(\"CPU\" , \"i7\" , False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgdspR8Dq6SM",
        "outputId": "92e4c65a-1b96-4a7e-92c9-5713ea1a339c"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded alexnet\n",
            "Calculating latency for alexnet\n",
            "Loaded vgg11\n",
            "Calculating latency for vgg11\n",
            "Loaded vgg11_bn\n",
            "Calculating latency for vgg11_bn\n",
            "Loaded vgg13\n",
            "Calculating latency for vgg13\n",
            "Loaded vgg13_bn\n",
            "Calculating latency for vgg13_bn\n",
            "Loaded vgg16\n",
            "Calculating latency for vgg16\n",
            "Loaded vgg16_bn\n",
            "Calculating latency for vgg16_bn\n",
            "Loaded vgg19\n",
            "Calculating latency for vgg19\n",
            "Loaded vgg19_bn\n",
            "Calculating latency for vgg19_bn\n",
            "Loaded resnet18\n",
            "Calculating latency for resnet18\n",
            "Loaded resnet34\n",
            "Calculating latency for resnet34\n",
            "Loaded resnet50\n",
            "Calculating latency for resnet50\n",
            "Loaded resnet101\n",
            "Calculating latency for resnet101\n",
            "Loaded resnet152\n",
            "Calculating latency for resnet152\n",
            "Loaded densenet121\n",
            "Calculating latency for densenet121\n",
            "Loaded densenet169\n",
            "Calculating latency for densenet169\n",
            "Loaded densenet161\n",
            "Calculating latency for densenet161\n",
            "Loaded densenet201\n",
            "Calculating latency for densenet201\n",
            "Loaded googlenet\n",
            "Calculating latency for googlenet\n",
            "Loaded wide_resnet50_2\n",
            "Calculating latency for wide_resnet50_2\n",
            "Loaded wide_resnet101_2\n",
            "Calculating latency for wide_resnet101_2\n",
            "Loaded alexnet1\n",
            "Calculating latency for alexnet1\n",
            "Loaded alexnet2\n",
            "Calculating latency for alexnet2\n",
            "Loaded alexnet3\n",
            "Calculating latency for alexnet3\n",
            "Loaded alexnet4\n",
            "Calculating latency for alexnet4\n",
            "Loaded alexnet5\n",
            "Calculating latency for alexnet5\n",
            "Loaded alexnet6\n",
            "Calculating latency for alexnet6\n",
            "Loaded alexnet7\n",
            "Calculating latency for alexnet7\n",
            "Loaded alexnet8\n",
            "Calculating latency for alexnet8\n",
            "Loaded alexnet9\n",
            "Calculating latency for alexnet9\n",
            "Loaded alexnet10\n",
            "Calculating latency for alexnet10\n",
            "Loaded alexnet11\n",
            "Calculating latency for alexnet11\n",
            "Loaded alexnet12\n",
            "Calculating latency for alexnet12\n",
            "Loaded alexnet13\n",
            "Calculating latency for alexnet13\n",
            "Loaded alexnet14\n",
            "Calculating latency for alexnet14\n",
            "Loaded alexnet15\n",
            "Calculating latency for alexnet15\n",
            "Loaded alexnet16\n",
            "Calculating latency for alexnet16\n",
            "Loaded alexnet17\n",
            "Calculating latency for alexnet17\n",
            "Loaded alexnet18\n",
            "Calculating latency for alexnet18\n",
            "Loaded alexnet19\n",
            "Calculating latency for alexnet19\n",
            "Loaded alexnet20\n",
            "Calculating latency for alexnet20\n",
            "Loaded alexnet21\n",
            "Calculating latency for alexnet21\n",
            "Loaded alexnet22\n",
            "Calculating latency for alexnet22\n",
            "Loaded alexnet23\n",
            "Calculating latency for alexnet23\n",
            "Loaded alexnet24\n",
            "Calculating latency for alexnet24\n",
            "Loaded alexnet25\n",
            "Calculating latency for alexnet25\n",
            "Loaded alexnet26\n",
            "Calculating latency for alexnet26\n",
            "Loaded alexnet27\n",
            "Calculating latency for alexnet27\n",
            "Loaded alexnet28\n",
            "Calculating latency for alexnet28\n",
            "Loaded alexnet29\n",
            "Calculating latency for alexnet29\n",
            "Loaded alexnet30\n",
            "Calculating latency for alexnet30\n",
            "Loaded alexnet31\n",
            "Calculating latency for alexnet31\n",
            "Loaded alexnet32\n",
            "Calculating latency for alexnet32\n",
            "Loaded alexnet33\n",
            "Calculating latency for alexnet33\n",
            "Loaded alexnet34\n",
            "Calculating latency for alexnet34\n",
            "Loaded alexnet35\n",
            "Calculating latency for alexnet35\n",
            "Loaded alexnet36\n",
            "Calculating latency for alexnet36\n",
            "Loaded alexnet37\n",
            "Calculating latency for alexnet37\n",
            "Loaded vgg1\n",
            "Calculating latency for vgg1\n",
            "Loaded vgg2\n",
            "Calculating latency for vgg2\n",
            "Loaded vgg3\n",
            "Calculating latency for vgg3\n",
            "Loaded vgg4\n",
            "Calculating latency for vgg4\n",
            "Loaded vgg5\n",
            "Calculating latency for vgg5\n",
            "Loaded vgg6\n",
            "Calculating latency for vgg6\n",
            "Loaded vgg7\n",
            "Calculating latency for vgg7\n",
            "Loaded vgg8\n",
            "Calculating latency for vgg8\n",
            "Loaded vgg9\n",
            "Calculating latency for vgg9\n",
            "Loaded vgg10\n",
            "Calculating latency for vgg10\n",
            "Loaded vgg11\n",
            "Calculating latency for vgg11\n",
            "Loaded vgg12\n",
            "Calculating latency for vgg12\n",
            "Loaded vgg13\n",
            "Calculating latency for vgg13\n",
            "Loaded vgg14\n",
            "Calculating latency for vgg14\n",
            "Loaded vgg15\n",
            "Calculating latency for vgg15\n",
            "Loaded vgg16\n",
            "Calculating latency for vgg16\n",
            "Loaded vgg17\n",
            "Calculating latency for vgg17\n",
            "Loaded vgg18\n",
            "Calculating latency for vgg18\n",
            "Loaded vgg19\n",
            "Calculating latency for vgg19\n",
            "Loaded vgg20\n",
            "Calculating latency for vgg20\n",
            "Loaded vgg21\n",
            "Calculating latency for vgg21\n",
            "Loaded vgg22\n",
            "Calculating latency for vgg22\n",
            "Loaded vgg23\n",
            "Calculating latency for vgg23\n",
            "Loaded vgg24\n",
            "Calculating latency for vgg24\n",
            "Loaded vgg25\n",
            "Calculating latency for vgg25\n",
            "Loaded vgg26\n",
            "Calculating latency for vgg26\n",
            "Loaded vgg27\n",
            "Calculating latency for vgg27\n",
            "Loaded vgg28\n",
            "Calculating latency for vgg28\n",
            "Loaded vgg29\n",
            "Calculating latency for vgg29\n",
            "Loaded vgg30\n",
            "Calculating latency for vgg30\n",
            "Loaded vgg31\n",
            "Calculating latency for vgg31\n",
            "Loaded resnet1\n",
            "Calculating latency for resnet1\n",
            "Loaded resnet2\n",
            "Calculating latency for resnet2\n",
            "Loaded resnet3\n",
            "Calculating latency for resnet3\n",
            "Loaded resnet4\n",
            "Calculating latency for resnet4\n",
            "Loaded resnet5\n",
            "Calculating latency for resnet5\n",
            "Loaded resnet6\n",
            "Calculating latency for resnet6\n",
            "Loaded resnet7\n",
            "Calculating latency for resnet7\n",
            "Loaded resnet8\n",
            "Calculating latency for resnet8\n",
            "Loaded resnet9\n",
            "Calculating latency for resnet9\n",
            "Loaded resnet10\n",
            "Calculating latency for resnet10\n",
            "Loaded resnet11\n",
            "Calculating latency for resnet11\n",
            "Loaded resnet12\n",
            "Calculating latency for resnet12\n",
            "Loaded resnet13\n",
            "Calculating latency for resnet13\n",
            "Loaded resnet14\n",
            "Calculating latency for resnet14\n",
            "Loaded resnet15\n",
            "Calculating latency for resnet15\n",
            "Loaded resnet16\n",
            "Calculating latency for resnet16\n",
            "Loaded resnet17\n",
            "Calculating latency for resnet17\n",
            "Calculated hardware latency\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cFUOqewpECoF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}